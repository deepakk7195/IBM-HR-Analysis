{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a model for the HR department to predict the Attrition and give the insights from the data\n",
    "# about the important factors associated with the attrition so that HR can take the corrective or\n",
    "# previntive measures to stop or control the attrition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from urllib.request import urlopen \n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from six import StringIO \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/DeepaK/Desktop/My Folder/My Learnings/HR_Employee_Attrition_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22360\\3176261948.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/DeepaK/Desktop/My Folder/My Learnings/HR_Employee_Attrition_Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/DeepaK/Desktop/My Folder/My Learnings/HR_Employee_Attrition_Data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/DeepaK/Desktop/My Folder/My Learnings/HR_Employee_Attrition_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting features into a list\n",
    "\n",
    "dx = ['Yes', 'No']\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating % of employees having Attrition labels as Yes and No. This also removes null / missing value\n",
    "# possibility in Target Variable (TV).\n",
    "\n",
    "df[df.Attrition.isin(['Yes', 'No'])].shape[0]/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding for the TV\n",
    "\n",
    "df['Attrition'] = df['Attrition'].map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Null / Missing Checking & Removal \n",
    "\n",
    "totalnulls = df.isnull().sum().sort_values(ascending=True)\n",
    "missing_data = pd.concat([totalnulls], axis=1, keys=['Totalnulls'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Checking for the 3 unwanted features: EmployeeCount, Over18, StandardHours as have same values throughout the features.\n",
    "\n",
    "print('EmployeeCount unique values: ', df['EmployeeCount'].unique())\n",
    "print('Over18 unique values: ',df['Over18'].unique())\n",
    "print('StandardHours unique values:',df['StandardHours'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Thus dropping these features\n",
    "\n",
    "mydf = df.drop(['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber'], axis = 1)\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting total count of Attrition in the total dataset\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "sns.countplot('Attrition', data = mydf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating % Attrition\n",
    "\n",
    "attrpc = mydf['Attrition'].value_counts()[1]/mydf['Attrition'].count()*100\n",
    "attrpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution of 1st feature Age against Attrition\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.distplot(mydf['Age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition Vs Age to check any relationship to generate an insight.\n",
    "\n",
    "plt.figure(figsize = (16,6))\n",
    "sns.swarmplot(y = 'Age', x = 'Attrition', data = mydf, hue = 'Attrition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 1: The Swarmplot shows Agewise, Atrrition is highest amongst Age group 28 - 34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution of Business Travel feature.\n",
    "\n",
    "plt.figure(figsize = (8,2))\n",
    "print(mydf['BusinessTravel'].value_counts())\n",
    "sns.countplot(x= 'BusinessTravel', data = mydf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition Vs Business travel to check any relationship to generate an insight.\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.swarmplot(x= 'Attrition', y='Age',  data = mydf, hue = 'BusinessTravel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 2: Attrition is highest among age group 30-32. This section also travels frequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution for next feature Departmemnt\n",
    "\n",
    "print(mydf['Department'].value_counts())\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.countplot(mydf['Department'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting department wise count of all 3 Business travel categories\n",
    "\n",
    "departmentgrp = mydf.groupby(by = 'Department')\n",
    "\n",
    "#HR\n",
    "df1 = departmentgrp.get_group('Human Resources')['BusinessTravel'].value_counts()\n",
    "df1 = pd.DataFrame(df1)\n",
    "df1 = df1.reset_index()\n",
    "df1['Department'] = 'HR'\n",
    "df1\n",
    "\n",
    "# RnD\n",
    "\n",
    "df2 = departmentgrp.get_group('Research & Development')['BusinessTravel'].value_counts()\n",
    "df2 = df2.to_frame().reset_index()\n",
    "df2['Department'] = 'R&D'\n",
    "df3 = df1.append(df2, ignore_index=True)\n",
    "df3\n",
    "\n",
    "# Sales\n",
    "\n",
    "df2 = departmentgrp.get_group('Sales')['BusinessTravel'].value_counts()\n",
    "df2 = df2.to_frame().reset_index()\n",
    "df2['Department'] = 'Sales'\n",
    "df4 = df3.append(df2, ignore_index=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting department data against travel\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.barplot(x= 'Department', y = 'BusinessTravel' , data = df4, hue = 'index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating attrition % for each department\n",
    "\n",
    "#Sales\n",
    "attrbysales = departmentgrp.get_group('Sales')['Attrition'].value_counts()\n",
    "#HR\n",
    "attrbyHR = departmentgrp.get_group('Human Resources')['Attrition'].value_counts()\n",
    "#RnD\n",
    "attrbyRnD = departmentgrp.get_group('Research & Development')['Attrition'].value_counts()\n",
    "\n",
    "attrbydept = pd.DataFrame(columns = ['Department', 'Attrition'])\n",
    "\n",
    "attrbydept.loc[len(attrbydept)] = [\"Sales\", attrbysales[1]/(attrbysales.sum())*100]\n",
    "attrbydept.loc[len(attrbydept)] = [\"HR\",(attrbyHR[1]/attrbyHR.sum())*100]\n",
    "attrbydept.loc[len(attrbydept)] = [\"R&D\",(attrbyRnD[1]/attrbyRnD.sum())*100]\n",
    "attrbydept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Attrition% for each department to find any relationship to generate an insight\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.barplot(x= 'Department', y = 'Attrition' , data = attrbydept, hue = 'Department')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 3: Sales Department is registering highest Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Attrition against EnvironmentSatisfaction level\n",
    "\n",
    "narr = mydf.EnvironmentSatisfaction.unique()\n",
    "arr = np.sort(narr)\n",
    "EnvironmentSatisfaction = pd.Series(arr)\n",
    "EnvironmentSatisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trydf = pd.DataFrame(columns = ['Attrition', 'Count']) \n",
    "trydf['EnvironmentSatisfaction'] = EnvironmentSatisfaction\n",
    "trydf\n",
    "v = trydf[list(trydf.columns)[-1]]\n",
    "trydf = trydf.drop(['EnvironmentSatisfaction'], axis = 1)\n",
    "trydf.insert(0,'EnvironmentSatisfaction',v)\n",
    "trydf['Attrition'] = 1\n",
    "\n",
    "occur = mydf.groupby(['EnvironmentSatisfaction', 'Attrition']).size()\n",
    "\n",
    "trydf.Count[0] = occur[1,1]\n",
    "trydf.Count[1]= occur[2,1]\n",
    "trydf.Count[2]= occur[3,1]\n",
    "trydf.Count[3]= occur[4,1]\n",
    "trydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition vs Environmentsatisfaction to generate insight\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.barplot(x= 'EnvironmentSatisfaction', y = 'Count' , data = trydf, hue = 'EnvironmentSatisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttrG = mydf.groupby(['Attrition', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Attrition Against Gender\n",
    "\n",
    "df1 = mydf.groupby(['Attrition','Gender']).size().reset_index().rename(columns={0:'Count'})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoAttr = df1[df1['Attrition'] == 0].index\n",
    "NoAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(NoAttr, inplace = True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition Vs Gender to check any relationship to generate an insight\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.barplot(x= 'Gender', y = 'Count' , data = df1, hue = 'Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 4: Male have higher Attrition rate than female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Attrition against job level\n",
    "\n",
    "JLdf = mydf.groupby(['Attrition','JobLevel']).size().reset_index().rename(columns={0:'Count'})\n",
    "JLdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoAttr = JLdf[JLdf['Attrition'] == 0].index\n",
    "JLdf\n",
    "JLdf1 = JLdf.drop(NoAttr)\n",
    "JLdf1 = JLdf1.reset_index()\n",
    "JLdf1['Count'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attritionpc = [int(100 * JLdf1['Count'][0] / (JLdf1['Count'][0] + JLdf['Count'][0])),\n",
    "               int(100 * JLdf1['Count'][1] / (JLdf1['Count'][1] + JLdf['Count'][1])),\n",
    "               int(100 * JLdf1['Count'][2] / (JLdf1['Count'][2] + JLdf['Count'][2])),\n",
    "               int(100 * JLdf1['Count'][3] / (JLdf1['Count'][3] + JLdf['Count'][3])),\n",
    "               int(100 * JLdf1['Count'][4] / (JLdf1['Count'][4] + JLdf['Count'][4]))\n",
    "              ] \n",
    "Attritionpc\n",
    "JLdf1['Attrition %'] = Attritionpc\n",
    "JLdf1\n",
    "JLdf1 = JLdf1.drop('index', axis = 1)\n",
    "JLdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition % Against Job level to check any relationship to generate an insight\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.barplot(x= 'Attrition', y = 'Attrition %' , data = JLdf1, hue = 'JobLevel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 5: Employees belonging to Job Level 1 are exiting the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition against Monthly Income to check any relationship to generate an insight\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.swarmplot(x= 'Attrition', y = 'MonthlyIncome' , data = mydf, hue= 'MaritalStatus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 6: Attrition is highest among employeeswho are Single. Morevoer, Bulk Attrition is happening with respect to the employees earning between 2500 to 2750."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Age vs monthly income\n",
    "\n",
    "plt.figure(figsize = (16,6))\n",
    "sns.regplot(x= 'Age', y = 'MonthlyIncome' , data = mydf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Insight 7: Looks like Age & Monthly Income features are having almost Linear Relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Salary hike and plotting against Attrition to generate an insight\n",
    "\n",
    "mydf['PercentSalaryHike'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,3))\n",
    "sns.distplot(mydf['PercentSalaryHike'], kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 8: Bulk Salary hike is < 15%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saldf = mydf.groupby(['PercentSalaryHike', 'Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Histogram of Count Vs PercentSalaryHike to check any relationship to generate an insight\n",
    "\n",
    "plt.figure(figsize = (16,3))\n",
    "plt.bar(saldf.PercentSalaryHike, saldf.Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 9: If hike is < 13%, Attiriton is very high. On other hand, it is very low if the hike is > 13. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Attrition Vs JobSatisfaction to check any relationship to generate an insight\n",
    "\n",
    "JSdf = mydf.groupby(['Attrition','JobSatisfaction']).size().reset_index().rename(columns={0:'Count'})\n",
    "JSdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoAttr = JSdf[JSdf['Attrition'] == 0].index\n",
    "JSdf\n",
    "JSdf1 = JSdf.drop(NoAttr)\n",
    "JSdf1 = JSdf1.reset_index().drop(['index'], axis = 1)\n",
    "JSdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attritionpc = [int(100 * JSdf1['Count'][0] / (JSdf1['Count'][0] + JSdf['Count'][0])),\n",
    "               int(100 * JSdf1['Count'][1] / (JSdf1['Count'][1] + JSdf['Count'][1])),\n",
    "               int(100 * JSdf1['Count'][2] / (JSdf1['Count'][2] + JSdf['Count'][2])),\n",
    "               int(100 * JSdf1['Count'][3] / (JSdf1['Count'][3] + JSdf['Count'][3])),\n",
    "              ] \n",
    "Attritionpc\n",
    "JSdf1['Attrition %'] = Attritionpc\n",
    "JSdf1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Attrition against JobSatisfactionelevel\n",
    "\n",
    "plt.figure(figsize = (16,6))\n",
    "sns.barplot(y = 'Attrition %', x = 'JobSatisfaction', data = JSdf1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 10: We can infer an Inverse Linear Relationship. As the Job Satisfaction level is increasing, Attrition is decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Random Forest Classifier as per RF code on mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing data: Encoding\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preprocessor(df):\n",
    "    res_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    res_df[\"Attrition\"] = le.fit_transform(res_df[\"Attrition\"])\n",
    "    res_df[\"BusinessTravel\"] = le.fit_transform(res_df[\"BusinessTravel\"])\n",
    "    res_df[\"Department\"] = le.fit_transform(res_df[\"Department\"])\n",
    "    res_df[\"EducationField\"] = le.fit_transform(res_df[\"EducationField\"])\n",
    "    res_df[\"Gender\"] = le.fit_transform(res_df[\"Gender\"])\n",
    "    res_df[\"JobRole\"] = le.fit_transform(res_df[\"JobRole\"])\n",
    "    res_df[\"MaritalStatus\"] = le.fit_transform(res_df[\"MaritalStatus\"])\n",
    "    res_df[\"OverTime\"] = le.fit_transform(res_df[\"OverTime\"])\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = preprocessor(mydf)\n",
    "encoded_df.shape\n",
    "x = encoded_df.drop(['Attrition'],axis =1).values    # Dropping Target Variable\n",
    "y = encoded_df['Attrition'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregating the Independent and the dependant variable\n",
    "\n",
    "y = encoded_df[\"Attrition\"].values\n",
    "X = encoded_df.drop([\"Attrition\"],axis =1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into Training & Testing\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size =0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Random Forest \n",
    "\n",
    "myhrmodel = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide n_estimator using OOBER\n",
    "\n",
    "myhrmodel.set_params(warm_start=False, \n",
    "                  oob_score=True)\n",
    "\n",
    "min_estimators = 15\n",
    "max_estimators = 500\n",
    "\n",
    "error_rate = {}\n",
    "\n",
    "for i in range(min_estimators, max_estimators + 1):\n",
    "    myhrmodel.set_params(n_estimators=i)\n",
    "    myhrmodel.fit(x_train, y_train)\n",
    "\n",
    "    oob_error = 1 - myhrmodel.oob_score_\n",
    "    error_rate[i] = oob_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to a pandas series for easy plotting \n",
    "oob_series = pd.Series(error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting n_estimator Vs OOBER to determine optimal n_estimator.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax.set_facecolor('#fafafa')\n",
    "\n",
    "oob_series.plot(kind='line',color = 'red')\n",
    "plt.axhline(0.055, color='#875FDB',linestyle='--')\n",
    "plt.axhline(0.05, color='#875FDB',linestyle='--')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB Error Rate')\n",
    "plt.title('OOB Error Rate Across various Forest sizes \\n(From {} to {} trees)'.format(min_estimators, max_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the decision tree model with tree size 300 as we can see from above graph, OOBER is stabilizing around 300.\n",
    "\n",
    "myhrmodel = RandomForestClassifier(n_estimators = 300, random_state = 0)\n",
    "myhrmodel.fit(x_train, y_train)\n",
    "myhrmodel_score_train = myhrmodel.score(x_train, y_train)\n",
    "print(\"Training score: \", myhrmodel_score_train)\n",
    "myhrmodel_score_test = myhrmodel.score(x_test, y_test)\n",
    "print(\"Testing score: \", myhrmodel_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Predictions of Attritions against X_test\n",
    "\n",
    "HRPred = myhrmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conf_mat(y_test, HRPred):\n",
    "    \"\"\"Function returns confusion matrix comparing two arrays\"\"\"\n",
    "    \n",
    "    if (len(y_test.shape) != len(HRPred.shape) == 1):\n",
    "        return print('Arrays entered are not 1-D.\\nPlease enter the correctly sized sets.')\n",
    "    \n",
    "    elif (y_test.shape != HRPred.shape):\n",
    "        return print('Number of values inside the Arrays are not equal to each other.\\nPlease make sure the array has the same number of instances.')\n",
    "    else:\n",
    "        # Set Metrics\n",
    "        test_crosstb_comp = pd.crosstab(index = y_test,\n",
    "                                        columns = HRPred)\n",
    "        \n",
    "        # Changed for Future deprecation of as_matrix\n",
    "        test_crosstb = test_crosstb_comp.values\n",
    "        return test_crosstb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = create_conf_mat(y_test, HRPred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Actual vs. Predicted Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing confusion matrix\n",
    "print (confusion_matrix(y_test, HRPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_HR = myhrmodel.score(x_test, y_test)\n",
    "\n",
    "print(\"Here is our mean accuracy on the test set:\\n {0:.3f}\".format(accuracy_HR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we calculate the test error rate.\n",
    "\n",
    "test_error_rate_HR = 1 - accuracy_HR\n",
    "print(\"The test error rate for our model is:\\n {0: .4f}\".format(test_error_rate_HR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We grab the second array from the output which corresponds to  the predicted probabilites of positive classes \n",
    "# Ordered wrt fit.classes_ in our case [0, 1] where 1 is our positive class\n",
    "\n",
    "predictions_prob = myhrmodel.predict_proba(x_test)[:, 1]\n",
    "\n",
    "fpr2, tpr2, _  = roc_curve(y_test,\n",
    "                          predictions_prob,\n",
    "                          pos_label = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_HR = auc(fpr2, tpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc, estimator, xlim = None, ylim = None):\n",
    "   \n",
    "    my_estimators = {'knn': ['Kth Nearest Neighbor', 'deeppink'],\n",
    "                     'rf': ['Random Forest', 'red'],\n",
    "                     'nn': ['Neural Network', 'purple']\n",
    "                    }\n",
    "\n",
    "    try:\n",
    "        plot_title = my_estimators[estimator][0]\n",
    "        color_value = my_estimators[estimator][1]\n",
    "    except KeyError as e:\n",
    "        \n",
    "        print(\"'{0}' does not correspond with the appropriate key inside the estimators dictionary. \\\n",
    "\\nPlease refer to function to check `my_estimators` dictionary.\".format(estimator))\n",
    "        \n",
    "        raise\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.set_facecolor('#fafafa')\n",
    "\n",
    "    plt.plot(fpr, tpr,\n",
    "             color=color_value,\n",
    "             linewidth=1)\n",
    "    plt.title('ROC Curve For {0} (AUC = {1: 0.3f})'\\\n",
    "              .format(plot_title, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2) # Add Diagonal line\n",
    "    plt.plot([0, 0], [1, 0], 'k--', lw=2, color = 'black')\n",
    "    plt.plot([1, 0], [1, 1], 'k--', lw=2, color = 'black')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(fpr2, tpr2, auc_HR, 'rf',\n",
    "               xlim=(-0.01, 1.05), \n",
    "               ylim=(0.001, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_report(predictions, alg_name):\n",
    "   \n",
    "    print('Classification Report for {0}:'.format(alg_name))\n",
    "    print(classification_report(predictions, \n",
    "            y_test, \n",
    "            target_names = dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = print_class_report(HRPred, 'Random Forest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
